## Implementación de la Red Neuronal

Para la implementación de la red neuronal se dividió en dos clases, _Neuron_ y _Layer_. 
_Neuron_ se encarga de modelar las Neuronas, en ella residen los pesos de la neurona, los datos recibidos y después de activados, estos 2 últimos utilizados para calcular las gradientes locales y actualizar los pesos.

Por otra parte, _Layer_ se encarga de modelar la capa completa. En ella se guarda una referencia a la capa anterior, a la capa siguiente. En esta clase se maneja todo lo que es la data del entramiento y predicción. Además de manejarse el Backpropagation directamente acá.

Adicionalmente se crearon funciones adicionales para el manejo de la data y obtención de las graficas necesarias.

## Parte 3
El dataset spam contiene 4601 correos enviados a Hewlett-Packard entre Junio y Julio de 1999. Los datos están organizados por 58 atributos, 57 son variables contínuas y la última es el parámetro que indica si un correo es spam o no.

De los otros 57 atributos, se tiene:

- 48 contienen la frecuencia en la que una _palabra_ específica aparece en un correo, entre todas las palabras del mismo. 
- 6 son para la frecuencia de ciertos caracteres en el correo, como lo son los caracteres `;, (, [ !, $` y `#`.
- 3 variables relacionadas con el conteo de letras mayúsculas en el texto, véase, la longitud más larga, cantidad de cadenas de texto escritas completamente en mayúsculas y cantidad total de letras mayúsculas en el texto.


Se dividió la data en 70% de entrenamiento y 30% para pruebas. La ejecución de los casos de prueba para la parte 3 se realizó de la siguiente manera:

Primero, se ejecutaron 500 épocas con las siguientes variaciones:

- Grado de confianza: 0.70, 0.80, 0.90.
- Alpha: 0.01, 0.0001 y 0.0001.
- Redes de 0, 1 y 2 capas ocultas con 1, 2 y 3 neuronas por capa. Esto es: [1], [1,1], [2,1], [3,1], [1,1,1], [1,2,1], [1,3,1], [2,1,1], [2,2,1], [2,3,1], [3,1,1], [3,2,1] y [3,3,1]

Aquí mostramos las tablas con los resultados (ordenados de menor a mayor en mínimo del error promedio)

Numero de iteraciones|Numero de capas|Neuronas por capa|Grado de confianza|Minimo del error promedio en entrenamiento|Maximo del error promedio en entrenamiento|Número de falsos positivos en el entrenamiento|Número de falsos negativos en el entrenamiento|Minimo del error promedio en pruebas|Maximo del error promedio en pruebas|Numero de falsos negativos en pruebas|Numero de falsos positivos en pruebas
---|----|---|---|---|---|---|----|----|----|---|-----|
500|1|[1]|0,7|0,01|0,085653098963736|0,244898998926552|57|340|0,0931975949695137|0,239835887973255|158|37
500|1|[1]|0,8|0,01|0,085653098963736|0,244898998926552|38|510|0,0931975949695137|0,239835887973255|244|28
500|1|[1]|0,9|0,01|0,085653098963736|0,244898998926552|21|769|0,0931975949695137|0,239835887973255|355|15
500|1|[1]|0,7|0,001|0,136128302311566|0,249455035538964|46|661|0,137367327364459|0,248928435499441|305|16
500|1|[1]|0,8|0,001|0,136128302311566|0,249455035538964|21|1013|0,137367327364459|0,248928435499441|446|6
500|1|[1]|0,9|0,001|0,136128302311566|0,249455035538964|10|1220|0,137367327364459|0,248928435499441|529|3
500|1|[1]|0,7|0,0001|0,21103023155632|0,24994644883431|5|1275|0,211627431186823|0,249891014537458|524|7
500|1|[1]|0,8|0,0001|0,21103023155632|0,24994644883431|0|1285|0,211627431186823|0,249891014537458|528|0
500|1|[1]|0,9|0,0001|0,21103023155632|0,24994644883431|0|1285|0,211627431186823|0,249891014537458|528|0
500|2|[1-1]|0,7|0,01|0,229607311601405|0,250106703065594|37|727|0,236059563567862|0,250628041898208|310|32
500|2|[1-1]|0,8|0,01|0,229607311601405|0,250106703065594|0|1285|0,236059563567862|0,250628041898208|528|0
500|2|[1-1]|0,9|0,01|0,229607311601405|0,250106703065594|0|1285|0,236059563567862|0,250628041898208|528|0
500|2|[2-1]|0,7|0,01|0,231394037202124|0,250186349565281|32|798|0,230584422171646|0,250183969145118|344|26
500|2|[2-1]|0,8|0,01|0,231394037202124|0,250186349565281|0|1256|0,230584422171646|0,250183969145118|557|0
500|2|[2-1]|0,9|0,01|0,231394037202124|0,250186349565281|0|1256|0,230584422171646|0,250183969145118|557|0
500|2|[3-1]|0,7|0,01|0,232175476546941|0,250239168017737|31|884|0,229543018725813|0,250111601777599|398|14
500|2|[3-1]|0,8|0,01|0,232175476546941|0,250239168017737|0|1258|0,229543018725813|0,250111601777599|555|0
500|2|[3-1]|0,9|0,01|0,232175476546941|0,250239168017737|0|1258|0,229543018725813|0,250111601777599|555|0
500|3|[3-2-1]|0,7|0,0001|0,235782228477037|0,249722837820446|0|1228|0,244154523395381|0,249645754216074|585|0
500|3|[3-2-1]|0,8|0,0001|0,235782228477037|0,249722837820446|0|1228|0,244154523395381|0,249645754216074|585|0
500|3|[3-2-1]|0,9|0,0001|0,235782228477037|0,249722837820446|0|1228|0,244154523395381|0,249645754216074|585|0
500|3|[2-2-1]|0,7|0,01|0,237527916931313|0,246978959867377|0|1250|0,241464058236596|0,249376622932001|563|0
500|3|[3-3-1]|0,7|0,0001|0,237703460624215|0,249641329142448|0|1254|0,240914123866108|0,249386502590792|559|0
500|3|[3-3-1]|0,8|0,0001|0,237703460624215|0,249641329142448|0|1254|0,240914123866108|0,249386502590792|559|0
500|3|[3-3-1]|0,9|0,0001|0,237703460624215|0,249641329142448|0|1254|0,240914123866108|0,249386502590792|559|0
500|3|[3-2-1]|0,7|0,01|0,238076745289119|0,24712615082526|0|1259|0,240155179000581|0,247883212409799|554|0
500|3|[3-2-1]|0,8|0,01|0,238076745289119|0,24712615082526|0|1259|0,240155179000581|0,247883212409799|554|0
500|3|[3-2-1]|0,9|0,01|0,238076745289119|0,24712615082526|0|1259|0,240155179000581|0,247883212409799|554|0
500|2|[2-1]|0,7|0,001|0,238143830441008|0,249942152800436|0|1246|0,242394094374383|0,250503822508591|567|0
500|2|[2-1]|0,8|0,001|0,238143830441008|0,249942152800436|0|1246|0,242394094374383|0,250503822508591|567|0
500|2|[2-1]|0,9|0,001|0,238143830441008|0,249942152800436|0|1246|0,242394094374383|0,250503822508591|567|0
500|3|[1-2-1]|0,7|0,01|0,238336911590909|0,247358838054852|0|1261|0,239935851089751|0,247929577309487|552|0
500|3|[1-2-1]|0,8|0,01|0,238336911590909|0,247358838054852|0|1261|0,239935851089751|0,247929577309487|552|0
500|3|[1-2-1]|0,9|0,01|0,238336911590909|0,247358838054852|0|1261|0,239935851089751|0,247929577309487|552|0
500|3|[3-1-1]|0,7|0,0001|0,238356083974239|0,249886189159918|0|1265|0,239161162270085|0,2497802269751|548|0
500|3|[3-1-1]|0,8|0,0001|0,238356083974239|0,249886189159918|0|1265|0,239161162270085|0,2497802269751|548|0
500|3|[3-1-1]|0,9|0,0001|0,238356083974239|0,249886189159918|0|1265|0,239161162270085|0,2497802269751|548|0
500|3|[1-1-1]|0,7|0,0001|0,238673900657826|0,249888090176213|0|1268|0,238852733724163|0,249777255057096|545|0
500|3|[1-1-1]|0,8|0,0001|0,238673900657826|0,249888090176213|0|1268|0,238852733724163|0,249777255057096|545|0
500|3|[1-1-1]|0,9|0,0001|0,238673900657826|0,249888090176213|0|1268|0,238852733724163|0,249777255057096|545|0
500|3|[2-1-1]|0,7|0,0001|0,238681927252506|0,249888809870017|0|1269|0,238646577833463|0,249776569426836|544|0
500|3|[2-1-1]|0,8|0,0001|0,238681927252506|0,249888809870017|0|1269|0,238646577833463|0,249776569426836|544|0
500|3|[2-1-1]|0,9|0,0001|0,238681927252506|0,249888809870017|0|1269|0,238646577833463|0,249776569426836|544|0
500|3|[1-3-1]|0,7|0,0001|0,238699942427816|0,249668859355714|0|1268|0,23888109366879|0,249345057251161|545|0
500|3|[1-3-1]|0,8|0,0001|0,238699942427816|0,249668859355714|0|1268|0,23888109366879|0,249345057251161|545|0
500|3|[1-3-1]|0,9|0,0001|0,238699942427816|0,249668859355714|0|1268|0,23888109366879|0,249345057251161|545|0
500|2|[3-1]|0,7|0,001|0,238848236961116|0,24997549439408|0|1260|0,240558194124828|0,250142105297623|553|0
500|2|[3-1]|0,8|0,001|0,238848236961116|0,24997549439408|0|1260|0,240558194124828|0,250142105297623|553|0
500|2|[3-1]|0,9|0,001|0,238848236961116|0,24997549439408|0|1260|0,240558194124828|0,250142105297623|553|0
500|3|[3-1-1]|0,7|0,01|0,238866864724218|0,245950442994601|0|1274|0,237673580924865|0,244960456628501|539|0
500|3|[3-1-1]|0,8|0,01|0,238866864724218|0,245950442994601|0|1274|0,237673580924865|0,244960456628501|539|0
500|3|[3-1-1]|0,9|0,01|0,238866864724218|0,245950442994601|0|1274|0,237673580924865|0,244960456628501|539|0
500|3|[1-2-1]|0,7|0,001|0,238963204998593|0,248070862229845|0|1272|0,23825668507895|0,246235546672791|541|0
500|3|[1-2-1]|0,8|0,001|0,238963204998593|0,248070862229845|0|1272|0,23825668507895|0,246235546672791|541|0
500|3|[1-2-1]|0,9|0,001|0,238963204998593|0,248070862229845|0|1272|0,23825668507895|0,246235546672791|541|0
500|3|[2-1-1]|0,7|0,001|0,239029174797756|0,249002925693632|0|1275|0,237683676712465|0,247938278942425|538|0
500|3|[2-1-1]|0,8|0,001|0,239029174797756|0,249002925693632|0|1275|0,237683676712465|0,247938278942425|538|0
500|3|[2-1-1]|0,9|0,001|0,239029174797756|0,249002925693632|0|1275|0,237683676712465|0,247938278942425|538|0
500|2|[2-1]|0,7|0,0001|0,239377384139797|0,249773767423523|0|1265|0,240083476358082|0,249564428468988|548|0
500|2|[2-1]|0,8|0,0001|0,239377384139797|0,249773767423523|0|1265|0,240083476358082|0,249564428468988|548|0
500|2|[2-1]|0,9|0,0001|0,239377384139797|0,249773767423523|0|1265|0,240083476358082|0,249564428468988|548|0
500|2|[1-1]|0,7|0,0001|0,239529954898355|0,249882024322775|0|1259|0,241283913342272|0,249785477087316|554|0
500|2|[1-1]|0,8|0,0001|0,239529954898355|0,249882024322775|0|1259|0,241283913342272|0,249785477087316|554|0
500|2|[1-1]|0,9|0,0001|0,239529954898355|0,249882024322775|0|1259|0,241283913342272|0,249785477087316|554|0
500|3|[1-1-1]|0,7|0,001|0,239569163835265|0,249034153711545|0|1282|0,236764400533122|0,247855656769153|531|0
500|3|[1-1-1]|0,8|0,001|0,239569163835265|0,249034153711545|0|1282|0,236764400533122|0,247855656769153|531|0
500|3|[1-1-1]|0,9|0,001|0,239569163835265|0,249034153711545|0|1282|0,236764400533122|0,247855656769153|531|0
500|3|[2-1-1]|0,7|0,01|0,239721161662634|0,246355555703434|0|1285|0,236213441473643|0,243876238894496|528|0
500|3|[2-1-1]|0,8|0,01|0,239721161662634|0,246355555703434|0|1285|0,236213441473643|0,243876238894496|528|0
500|3|[2-1-1]|0,9|0,01|0,239721161662634|0,246355555703434|0|1285|0,236213441473643|0,243876238894496|528|0
500|3|[2-2-1]|0,7|0,01|0,239802152870289|0,248187487713505|0|1285|0,236126718098583|0,245702420926008|528|0
500|3|[2-2-1]|0,8|0,01|0,239802152870289|0,248187487713505|0|1285|0,236126718098583|0,245702420926008|528|0
500|3|[2-2-1]|0,9|0,01|0,239802152870289|0,248187487713505|0|1285|0,236126718098583|0,245702420926008|528|0
500|3|[1-2-1]|0,7|0,0001|0,24022185177956|0,249808036646869|0|1292|0,235469341367567|0,249521200109781|521|0
500|3|[1-2-1]|0,8|0,0001|0,24022185177956|0,249808036646869|0|1292|0,235469341367567|0,249521200109781|521|0
500|3|[1-2-1]|0,9|0,0001|0,24022185177956|0,249808036646869|0|1292|0,235469341367567|0,249521200109781|521|0
500|3|[3-3-1]|0,7|0,01|0,240362212075637|0,249325805686097|0|1292|0,23537302617313|0,247169209526872|521|0
500|3|[3-3-1]|0,8|0,01|0,240362212075637|0,249325805686097|0|1292|0,23537302617313|0,247169209526872|521|0
500|3|[3-3-1]|0,9|0,01|0,240362212075637|0,249325805686097|0|1292|0,23537302617313|0,247169209526872|521|0
500|3|[1-3-1]|0,7|0,001|0,240371911576603|0,247634182352683|0|1294|0,23523258301569|0,244343227052718|519|0
500|3|[1-3-1]|0,8|0,001|0,240371911576603|0,247634182352683|0|1294|0,23523258301569|0,244343227052718|519|0
500|3|[1-3-1]|0,9|0,001|0,240371911576603|0,247634182352683|0|1294|0,23523258301569|0,244343227052718|519|0
500|3|[2-1-1]|0,7|0,01|0,240839262961571|0,247022427284675|0|1303|0,234019952022382|0,242972881054369|510|0
500|3|[2-1-1]|0,8|0,01|0,240839262961571|0,247022427284675|0|1303|0,234019952022382|0,242972881054369|510|0
500|3|[2-1-1]|0,9|0,01|0,240839262961571|0,247022427284675|0|1303|0,234019952022382|0,242972881054369|510|0
500|2|[1-1]|0,7|0,001|0,240994077492833|0,250011186631979|0|1282|0,238685689933838|0,250051827642776|531|0
500|2|[1-1]|0,8|0,001|0,240994077492833|0,250011186631979|0|1282|0,238685689933838|0,250051827642776|531|0
500|2|[1-1]|0,9|0,001|0,240994077492833|0,250011186631979|0|1282|0,238685689933838|0,250051827642776|531|0

De todas estas pruebas realizadas, se seleccionaron las que obtuvieron el mejor gráfico en su convergencia, así como las que obtuvieron la menor suma de falsos positivos y falsos negativos, lo cual indica una buena tasa de aciertos. Estos son:

- 1 neurona, 0.01 de tasa de aprendizaje y 70%, 80% y 90% de grado de confianza
- 1 neurona, 0.001 de tasa de aprendizaje y 70%, 80% y 90% de grado de confianza
- 2 neuronas en dos capas (1,1). Tasa de aprendizaje 0.001 y 0.0001.
- 3 neuronas en dos capas (2,1). Tasa de aprendizaje 0.001 y 0.0001.
- 3 neuronas en tres capas (1,1,1). Tasa de aprendizaje 0.001 y 0.0001
- 4 neuronas en tres capas (1,2,1). Tasa de aprendizaje 0.001 y 0.0001
- 5 neuronas en tres capas (1,3,1). Tasa de aprendizaje 0.001 y 0.0001
- 4 neuronas en tres capas (2,1,1). Tasa de aprendizaje 0.001 y 0.0001
- 7 neuronas en tres capas (3,3,1). Tasa de aprendizaje 0.001 y 0.000

Algo interesante que observamos es que el modelo con una sola neurona, tiene una convergencia buena para el hecho de tener tan pocas neuronas. A medida que se añaden neuronas el modelo empeora hasta que se llegan a 5 neuronas, cuando el modelo se vuelve a estabilizar y los gráficos dan una mejor convergencia.

Mostramos por ejemplo el caso del entrenamiento de una red neuronal de una sola neurona se comporta mejor que una red de dos neuronas con dos capas, ambas con 80% de grado de aceptación, 0.001 de tasa de aprendizaje y 5000 iteraciones:

Una neurona con una capa | Dos neuronas con dos capas |
------|----|
|<img src="images/capas_1_capasN_%5B1%5D_mean_train_LR_0.001_epoch_5000_TG_0.8.png" width=350px>|<img src="images/capas_2_capasN_%5B1-1%5D_mean_train_LR_0.001_epoch_5000_TG_0.8.png" width=350px>

Aquí, pasa lo mismo pero con ambas con 70% de grado de aceptación, 0.001 de tasa de aprendizaje y 5000 iteraciones:

Una neurona con una capa | Dos neuronas con dos capas |
------|----|
|<img src="images/capas_1_capasN_%5B1%5D_mean_train_LR_0.001_epoch_5000_TG_0.7.png" width=350px>|<img src="images/capas_2_capasN_%5B1-1%5D_mean_test_LR_0.001_epoch_5000_TG_0.7.png" width=350px>

Para cada experimento realizado, debe incluir tablas con:
* Error promedio, mínimo y máximo en el conjunto de entrenamiento y prueba.
* Cantidad de falsos positivos tanto en el conjunto de entrenamiento como de prueba. Un falso positivo en un clasificador binario es un ejemplo para el que la hipótesis incluye al ejemplo en la categoría clasificada, cuando no pertenece a ella en realidad.
* Cantidad de falsos negativos tanto en el conjunto de entrenamiento como de prueba. Un falso negativo en un clasificador binario es un ejemplo para el que la hipótesis excluye de la categoría clasificada, cuando en realidad sí pertenece a ella. 


Se requiere que realice experimentos para las siguientes topologías:

* Una única neurona, variando la tasa de aprendizaje para hallar la mejor hipótesis.
* Utilizando una capa oculta, variando la tasa de aprendizaje y probando con cuantas neuronas quiera en capa oculta.
* Utilizando dos capas ocultas, siguiendo la misma idea.

Se ra
